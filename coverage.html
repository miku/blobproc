
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>blobproc: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/miku/blobproc/blob.go (74.0%)</option>
				
				<option value="file1">github.com/miku/blobproc/cmd/blobproc/main.go (0.0%)</option>
				
				<option value="file2">github.com/miku/blobproc/cmd/blobprocd/main.go (0.0%)</option>
				
				<option value="file3">github.com/miku/blobproc/fileutils/copy.go (56.0%)</option>
				
				<option value="file4">github.com/miku/blobproc/misc.go (28.6%)</option>
				
				<option value="file5">github.com/miku/blobproc/pdfextract.go (73.2%)</option>
				
				<option value="file6">github.com/miku/blobproc/pdfinfo/parse.go (67.4%)</option>
				
				<option value="file7">github.com/miku/blobproc/pidfile/pidfile.go (87.5%)</option>
				
				<option value="file8">github.com/miku/blobproc/runner.go (69.2%)</option>
				
				<option value="file9">github.com/miku/blobproc/service.go (4.8%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package blobproc

import (
        "bytes"
        "context"
        "crypto/sha1"
        "fmt"
        "io"
        "strings"

        "github.com/minio/minio-go/v7"
        "github.com/minio/minio-go/v7/pkg/credentials"
)

// WrapS3 slightly wraps I/O around our S3 store with convenience methods.
type WrapS3 struct {
        Client *minio.Client
}

// WrapS3Options mostly contains pass through options for minio client.
// Keys from environment, e.g. ...BLOB_ACCESS_KEY
type WrapS3Options struct {
        AccessKey     string
        SecretKey     string
        DefaultBucket string
        UseSSL        bool
}

// NewWrapS3 creates a new, slim wrapper around S3.
func NewWrapS3(endpoint string, opts *WrapS3Options) (*WrapS3, error) <span class="cov8" title="1">{
        client, err := minio.New(endpoint,
                &amp;minio.Options{
                        Creds:  credentials.NewStaticV4(opts.AccessKey, opts.SecretKey, ""),
                        Secure: opts.UseSSL,
                },
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;WrapS3{
                Client: client,
        }, nil</span>
}

// BlobRequestOptions wraps the blob request options, both for setting and
// retrieving a blob.
//
// Currently used folder names:
//
// - "pdf" for thumbnails
// - "xml_doc" for TEI-XML
// - "html_body" for HTML TEI-XML
// - "unknown" for generic
//
// Default bucket is "sandcrawler-dev", other buckets via infra:
//
// - "sandcrawler" for sandcrawler_grobid_bucket
// - "thumbnail" for sandcrawler_thumbnail_bucket
// - "sandcrawler" for sandcrawler_text_bucket
type BlobRequestOptions struct {
        Folder  string
        Blob    []byte
        SHA1Hex string
        Ext     string
        Prefix  string
        Bucket  string
}

// PutBlobResponse wraps a blob put request response.
type PutBlobResponse struct {
        Bucket     string
        ObjectPath string
}

// blobPath returns the path for a given folder, content hash, extension and
// prefix. Panic if sha1hex is not a length 40 string.
func blobPath(folder, sha1hex, ext, prefix string) string <span class="cov8" title="1">{
        if len(ext) &gt; 0 &amp;&amp; !strings.HasPrefix(ext, ".") </span><span class="cov8" title="1">{
                ext = "." + ext
        }</span>
        <span class="cov8" title="1">return fmt.Sprintf("%s%s/%s/%s/%s%s",
                prefix, folder, sha1hex[0:2], sha1hex[2:4], sha1hex, ext)</span>
}

// PutBlob takes a data to be put into S3 and saves it.
func (wrap *WrapS3) PutBlob(ctx context.Context, req *BlobRequestOptions) (*PutBlobResponse, error) <span class="cov8" title="1">{
        if req.SHA1Hex == "" </span><span class="cov8" title="1">{
                h := sha1.New()
                _, err := io.Copy(h, bytes.NewReader(req.Blob))
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">req.SHA1Hex = fmt.Sprintf("%x", h.Sum(nil))</span>
        }
        <span class="cov8" title="1">if len(req.SHA1Hex) != 40 </span><span class="cov0" title="0">{
                return nil, ErrInvalidHash
        }</span>
        <span class="cov8" title="1">objPath := blobPath(req.Folder, req.SHA1Hex, req.Ext, req.Prefix)
        if req.Bucket == "" </span><span class="cov8" title="1">{
                req.Bucket = DefaultBucket
        }</span>
        <span class="cov8" title="1">ok, err := wrap.Client.BucketExists(context.Background(), req.Bucket)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if !ok </span><span class="cov8" title="1">{
                opts := minio.MakeBucketOptions{}
                if err := wrap.Client.MakeBucket(ctx, req.Bucket, opts); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        }
        <span class="cov8" title="1">contentType := "application/octet-stream"
        if strings.HasSuffix(req.Ext, ".xml") </span><span class="cov8" title="1">{
                contentType = "application/xml"
        }</span>
        <span class="cov8" title="1">if strings.HasSuffix(req.Ext, ".png") </span><span class="cov0" title="0">{
                contentType = "image/png"
        }</span>
        <span class="cov8" title="1">if strings.HasSuffix(req.Ext, ".jpg") || strings.HasSuffix(req.Ext, ".jpeg") </span><span class="cov0" title="0">{
                contentType = "image/jpeg"
        }</span>
        <span class="cov8" title="1">if strings.HasSuffix(req.Ext, ".txt") </span><span class="cov0" title="0">{
                contentType = "text/plain"
        }</span>
        <span class="cov8" title="1">opts := minio.PutObjectOptions{
                ContentType: contentType,
        }
        info, err := wrap.Client.PutObject(ctx, req.Bucket, objPath,
                bytes.NewReader(req.Blob), int64(len(req.Blob)), opts)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if info.Bucket != req.Bucket </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("[put] bucket mismatch: %v", info.Bucket)
        }</span>
        <span class="cov8" title="1">if info.Key != objPath </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("[put] key mismatch: %v", info.Key)
        }</span>
        <span class="cov8" title="1">return &amp;PutBlobResponse{
                Bucket:     info.Bucket,
                ObjectPath: info.Key,
        }, nil</span>
}

// GetBlob returns the object bytes given a blob request.
func (wrap *WrapS3) GetBlob(ctx context.Context, req *BlobRequestOptions) ([]byte, error) <span class="cov8" title="1">{
        objPath := blobPath(req.Folder, req.SHA1Hex, req.Ext, req.Prefix)
        if req.Bucket == "" </span><span class="cov0" title="0">{
                req.Bucket = DefaultBucket
        }</span>
        <span class="cov8" title="1">object, err := wrap.Client.GetObject(ctx, req.Bucket, objPath, minio.GetObjectOptions{})
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return io.ReadAll(object)</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">package main

import (
        "flag"
        "io/fs"
        "log/slog"
        "os"
        "path"
        "path/filepath"

        "github.com/adrg/xdg"
        "github.com/miku/blobproc"
        "github.com/miku/blobproc/pidfile"
        "github.com/miku/grobidclient"
)

var (
        spoolDir = flag.String("spool", path.Join(xdg.DataHome, "/webspool/spool"), "")
        pidFile  = flag.String("pidfile", path.Join(xdg.RuntimeDir, "webspool.pid"), "pidfile")
        logFile  = flag.String("log", "", "structured log output file, stderr if empty")
        debug    = flag.Bool("debug", false, "more verbose output")
        // GROBID related
        grobidHost        = flag.String("grobid", "http://localhost:8070", "grobid host, cf. https://is.gd/3wnssq")
        consolidateMode   = flag.Bool("consolidate-mode", false, "consolidate mode")
        maxGrobidFilesize = flag.Int64("max-grobid-filesize", 256*1024*1024, "max file size to send to grobid in bytes")
        // S3 related
        s3          = flag.String("s3", "", "S3 endpoint") // TODO: access key in env
        s3AccessKey = flag.String("s3-access-key", "minioadmin", "S3 access key")
        s3SecretKey = flag.String("s3-secret-key", "minioadmin", "S3 secret key")
)

func main() <span class="cov0" title="0">{
        flag.Parse()
        if err := pidfile.Write(*pidFile, os.Getpid()); err != nil </span><span class="cov0" title="0">{
                slog.Error("exiting", "err", err, "pidfile", "*pidFile")
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">var (
                logLevel = slog.LevelInfo
                h        slog.Handler
        )
        if *debug </span><span class="cov0" title="0">{
                logLevel = slog.LevelDebug
        }</span>
        <span class="cov0" title="0">switch </span>{
        case *logFile != "":<span class="cov0" title="0">
                f, err := os.OpenFile(*logFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("cannot open log", "err", err)
                        os.Exit(1)
                }</span>
                <span class="cov0" title="0">defer f.Close()
                h = slog.NewJSONHandler(f, &amp;slog.HandlerOptions{Level: logLevel})</span>
        default:<span class="cov0" title="0">
                h = slog.NewJSONHandler(os.Stderr, &amp;slog.HandlerOptions{Level: logLevel})</span>
        }
        <span class="cov0" title="0">logger := slog.New(h)
        slog.SetDefault(logger)
        grobid := grobidclient.New(*grobidHost)
        slog.Info("initialize grobid client", "host", *grobidHost)
        s3wrapper, err := blobproc.NewWrapS3(*s3, &amp;blobproc.WrapS3Options{
                AccessKey:     *s3AccessKey,
                SecretKey:     *s3SecretKey,
                DefaultBucket: "sandcrawler",
                UseSSL:        false,
        })
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("cannot access S3", "err", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">slog.Info("initialized s3 wrapper", "host", *s3)
        runner := &amp;blobproc.Runner{
                Grobid:            grobid,
                MaxGrobidFileSize: *maxGrobidFilesize,
                ConsolidateMode:   *consolidateMode,
                S3Wrapper:         s3wrapper,
        }
        err = filepath.Walk(*spoolDir, func(path string, info fs.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if info.IsDir() </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">slog.Info("processing", "path", path)
                if _, err := runner.RunGrobid(path); err != nil </span><span class="cov0" title="0">{
                        slog.Error("grobid failed", "err", err, "path", path)
                        return err
                }</span>
                <span class="cov0" title="0">if err := runner.RunPdfToText(path); err != nil </span><span class="cov0" title="0">{
                        slog.Error("pdftotext failed", "err", err, "path", path)
                        return err
                }</span>
                <span class="cov0" title="0">return nil</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                slog.Error("walk failed", "err", err)
                os.Exit(1)
        }</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">// blobprocd takes binary blobs via HTTP POST and save them to disk.
package main

import (
        "flag"
        "fmt"
        "io"
        "log"
        "log/slog"
        "net/http"
        "os"
        "path"
        "time"

        "github.com/adrg/xdg"
        "github.com/gorilla/handlers"
        "github.com/gorilla/mux"
        "github.com/miku/blobproc"
)

var (
        spoolDir   = flag.String("spool", path.Join(xdg.DataHome, "/webspool/spool"), "")
        listenAddr = flag.String("addr", "0.0.0.0:8000", "host port to listen on")
        timeout    = flag.Duration("T", 15*time.Second, "server timeout")

        banner        = `{"id": "blobprocd", "about": "Send your PDF payload to %s/spool - a 200 OK status only confirms receipt, not successful postprocessing, which may take more time. Check Location header for spool id."}`
        showVersion   = flag.Bool("v", false, "show version")
        debug         = flag.Bool("debug", false, "switch to log level DEBUG")
        accessLogFile = flag.String("access-log", "", "server access logfile, none if empty")
        logFile       = flag.String("log", "", "structured log output file, stderr if empty")
)

func main() <span class="cov0" title="0">{
        flag.Parse()
        if *showVersion </span><span class="cov0" title="0">{
                fmt.Println(blobproc.Version)
                os.Exit(0)
        }</span>
        <span class="cov0" title="0">var (
                logLevel        = slog.LevelInfo
                h               slog.Handler
                accessLogWriter io.Writer
        )
        if *debug </span><span class="cov0" title="0">{
                logLevel = slog.LevelDebug
        }</span>
        <span class="cov0" title="0">switch </span>{
        case *logFile != "":<span class="cov0" title="0">
                f, err := os.OpenFile(*logFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
                if err != nil </span><span class="cov0" title="0">{
                        log.Fatal(err)
                }</span>
                <span class="cov0" title="0">defer f.Close()
                h = slog.NewJSONHandler(f, &amp;slog.HandlerOptions{Level: logLevel})</span>
        default:<span class="cov0" title="0">
                h = slog.NewJSONHandler(os.Stderr, &amp;slog.HandlerOptions{Level: logLevel})</span>
        }
        <span class="cov0" title="0">logger := slog.New(h)
        slog.SetDefault(logger)
        switch </span>{
        case *accessLogFile != "":<span class="cov0" title="0">
                f, err := os.OpenFile(*accessLogFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
                if err != nil </span><span class="cov0" title="0">{
                        log.Fatal(err)
                }</span>
                <span class="cov0" title="0">defer f.Close()
                accessLogWriter = f</span>
        default:<span class="cov0" title="0">
                accessLogWriter = io.Discard</span>
        }
        <span class="cov0" title="0">svc := &amp;blobproc.WebSpoolService{
                Dir:        *spoolDir,
                ListenAddr: *listenAddr,
        }
        r := mux.NewRouter()
        r.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                _, err := fmt.Fprintf(w, banner+"\n", *listenAddr)
                if err != nil </span><span class="cov0" title="0">{
                        w.WriteHeader(http.StatusInternalServerError)
                }</span>
        })
        <span class="cov0" title="0">r.HandleFunc("/spool", svc.BlobHandler).Methods("POST", "PUT")
        r.HandleFunc("/spool", svc.SpoolListHandler).Methods("GET")
        r.HandleFunc("/spool/{id}", svc.SpoolStatusHandler).Methods("GET")
        loggedRouter := handlers.LoggingHandler(accessLogWriter, r)
        srv := &amp;http.Server{
                Handler:      loggedRouter,
                Addr:         *listenAddr,
                WriteTimeout: *timeout,
                ReadTimeout:  *timeout,
        }
        slog.Info("starting server at", "hostport", srv.Addr, "spool", *spoolDir)
        log.Fatal(srv.ListenAndServe())</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">package fileutils

import (
        "io"
        "io/ioutil"
        "os"
        "path/filepath"
)

// A Copier copies files.
// The operation of Copier's public functions are controled by its
// public fields. If none are set, the Copier behaves accoriding to
// the zero value rules of each public field.
type Copier struct {
}

// CopyFile copies the contents of src to dst atomically.
func (c *Copier) CopyFile(dst, src string) error <span class="cov8" title="1">{
        in, err := os.Open(src)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">defer in.Close()
        tmp, err := ioutil.TempFile(filepath.Dir(dst), "copyfile")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">_, err = io.Copy(tmp, in)
        if err != nil </span><span class="cov0" title="0">{
                tmp.Close()
                os.Remove(tmp.Name())
                return err
        }</span>
        <span class="cov8" title="1">if err := tmp.Close(); err != nil </span><span class="cov0" title="0">{
                os.Remove(tmp.Name())
                return err
        }</span>
        <span class="cov8" title="1">const perm = 0644
        if err := os.Chmod(tmp.Name(), perm); err != nil </span><span class="cov0" title="0">{
                os.Remove(tmp.Name())
                return err
        }</span>
        <span class="cov8" title="1">if err := os.Rename(tmp.Name(), dst); err != nil </span><span class="cov0" title="0">{
                os.Remove(tmp.Name())
                return err
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// CopyFile is a convenience method that calls CopyFile on a Copier
// zero value.
func CopyFile(dst, src string) error <span class="cov8" title="1">{
        var c Copier
        return c.CopyFile(dst, src)
}</span>
</pre>
		
		<pre class="file" id="file4" style="display: none">package blobproc

import (
        "crypto/md5"
        "crypto/sha1"
        "crypto/sha256"
        "encoding/hex"
        "errors"
        "hash"
        "io"
        "os"

        "github.com/gabriel-vasile/mimetype"
)

var ErrNoData = errors.New("no data")

// FileInfo groups checksum and size for a file. The checksums are all lowercase hex digests.
type FileInfo struct {
        Size      int64
        SHA1Hex   string
        SHA256Hex string
        MD5Hex    string
        Mimetype  string
}

// FromBytes creates a FileInfo object from bytes.
func (fi *FileInfo) FromBytes(p []byte) <span class="cov8" title="1">{
        var hasher = []hash.Hash{md5.New(), sha1.New(), sha256.New()}
        for _, h := range hasher </span><span class="cov8" title="1">{
                _, _ = h.Write(p)
        }</span>
        <span class="cov8" title="1">*fi = FileInfo{
                Size:      int64(len(p)),
                MD5Hex:    hex.EncodeToString(hasher[0].Sum(nil)),
                SHA1Hex:   hex.EncodeToString(hasher[1].Sum(nil)),
                SHA256Hex: hex.EncodeToString(hasher[2].Sum(nil)),
                Mimetype:  mimetype.Detect(p).String(),
        }</span>
}

// FromReader creates file info fields from metadata.
func (fi *FileInfo) FromReader(r io.Reader) error <span class="cov0" title="0">{
        b, err := io.ReadAll(r)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">fi.FromBytes(b)
        return nil</span>
}

// FromFile creates a FileInfo object from a path.
func (fi *FileInfo) FromFile(filename string) error <span class="cov0" title="0">{
        f, err := os.Open(filename)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer f.Close()
        return fi.FromReader(f)</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">package blobproc

import (
        "bytes"
        "encoding/json"
        "fmt"
        "io"
        "os"
        "os/exec"
        "slices"

        "github.com/miku/blobproc/pdfinfo"
)

// PDFExtractResult is the result of a text and thumbnail extraction from a
// PDF. Both are combined since previous implementation used the poppler
// library in one go for performance.
type PDFExtractResult struct {
        SHA1Hex        string            `json:"sha1hex,omitempty"`        // The SHA1 of the PDF, used later as key.
        Status         string            `json:"status,omitempty"`         // A free form status string.
        Err            error             `json:"err,omitempty"`            // Any error we encountered.
        FileInfo       *FileInfo         `json:"fileinfo,omitempty"`       // Size and checksums.
        Text           string            `json:"text,omitempty"`           // Fulltext as parsed with a tool, e.g. pdftotext.
        Page0Thumbnail []byte            `json:"page0thumbnail,omitempty"` // Thumbnail image, jpg format.
        MetaXML        string            `json:"metaxml,omitempty"`        // Unassigned.
        Metadata       *pdfinfo.Metadata `json:"metadata,omitempty"`       // New, grouped by tool, info about a pdf.
        PDFExtra       *pdfinfo.PDFExtra `json:"pdfextra,omitempty"`       // pdfextra, as provided by sandcrawler
        Source         json.RawMessage   `json:"source,omitempty"`         // Unassigned.
}

func (result *PDFExtractResult) HasPage0Thumbnail() bool <span class="cov0" title="0">{
        return len(result.Page0Thumbnail) &gt; 50
}</span>

// Dim in pixels, for thumbnail size.
type Dim struct {
        W int
        H int
}

// extractTextFromPDF returns the text of the PDF, uses pdftotext.
func extractTextFromPDF(filename string) ([]byte, error) <span class="cov8" title="1">{
        dst := filename + ".txt.wip"
        defer func() </span><span class="cov8" title="1">{
                _ = os.Remove(dst)
        }</span>()
        <span class="cov8" title="1">cmd := exec.Command("pdftotext", filename, dst)
        if err := cmd.Run(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return os.ReadFile(dst)</span>
}

// extractThumbnailFromPDF runs pdftoppm to render page0 of the PDF into an image.
func extractThumbnailFromPDF(filename string, dim Dim) ([]byte, error) <span class="cov8" title="1">{
        dst := filename + ".page0.wip"
        defer func() </span><span class="cov8" title="1">{
                _ = os.Remove(dst + ".jpg")
        }</span>()
        <span class="cov8" title="1">cmd := exec.Command("pdftoppm",
                "-jpeg",
                "-f", "1",
                "-l", "1",
                "-singlefile",
                "-scale-to-x", fmt.Sprintf("%d", dim.W),
                "-scale-to-y", fmt.Sprintf("%d", dim.H),
                filename,
                dst)
        if err := cmd.Run(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">b, err := os.ReadFile(dst + ".jpg") // TODO: fix filename
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return b, nil</span>
}

// extractPDFMetadata extracts the PDF info via pdfcpu as raw JSON bytes.
func extractPDFMetadata(filename string) (*pdfinfo.Metadata, error) <span class="cov8" title="1">{
        metadata, err := pdfinfo.ParseFile(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return metadata, nil</span>
}

func ProcessPDFFile(filename string, dim Dim, thumbType string) *PDFExtractResult <span class="cov8" title="1">{
        f, err := os.Open(filename)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;PDFExtractResult{
                        Err: err,
                }
        }</span>
        <span class="cov8" title="1">defer f.Close()
        b, err := io.ReadAll(f)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;PDFExtractResult{
                        Err: err,
                }
        }</span>
        <span class="cov8" title="1">return ProcessPDF(b, dim, thumbType)</span>
}

// ProcessPDF takes a blob and returns a pdf extract result. TODO: we can makes
// this faster by running various subprocesses in parallel.
func ProcessPDF(blob []byte, dim Dim, thumbType string) *PDFExtractResult <span class="cov8" title="1">{
        var fi = new(FileInfo)
        fi.FromBytes(blob)
        // Save PDF blob to a temporary file to run various cli tools over it.
        // Strangely, pdfcpu wants a file with a .pdf extension (-1).
        tf, err := os.CreateTemp("", "blobproc-pdf-*.pdf")
        if err != nil </span><span class="cov0" title="0">{
                return &amp;PDFExtractResult{
                        SHA1Hex:  fi.SHA1Hex,
                        Err:      err,
                        FileInfo: fi,
                }
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{
                _ = tf.Close()
                os.Remove(tf.Name())
        }</span>()
        <span class="cov8" title="1">_, err = io.Copy(tf, bytes.NewReader(blob))
        if err != nil </span><span class="cov0" title="0">{
                return &amp;PDFExtractResult{
                        SHA1Hex:  fi.SHA1Hex,
                        Err:      err,
                        FileInfo: fi,
                }
        }</span>
        // Prefilter non-pdf and bad pdf files.
        <span class="cov8" title="1">switch </span>{
        case fi.Mimetype != "application/pdf":<span class="cov8" title="1">
                return &amp;PDFExtractResult{
                        SHA1Hex:  fi.SHA1Hex,
                        Status:   "not-pdf",
                        Err:      fmt.Errorf("mimetype is %v", fi.Mimetype),
                        FileInfo: fi,
                }</span>
        case slices.Contains(BAD_PDF_SHA1HEX, fi.SHA1Hex):<span class="cov0" title="0">
                return &amp;PDFExtractResult{
                        SHA1Hex:  fi.SHA1Hex,
                        Status:   "bad-pdf",
                        Err:      fmt.Errorf("PDF known to cause processing issues"),
                        FileInfo: fi,
                }</span>
        }
        // Extract the fulltext.
        <span class="cov8" title="1">text, err := extractTextFromPDF(tf.Name())
        switch </span>{
        case err != nil:<span class="cov0" title="0">
                return &amp;PDFExtractResult{
                        SHA1Hex: fi.SHA1Hex,
                        Status:  "parse-error",
                        Err:     fmt.Errorf("text extraction failed: %w", err),
                }</span>
        case len(text) == 0:<span class="cov0" title="0">
                return &amp;PDFExtractResult{
                        SHA1Hex: fi.SHA1Hex,
                        Status:  "empty-pdf",
                        Err:     fmt.Errorf("zero length text"),
                }</span>
        }
        // Extract the thumbnail.
        <span class="cov8" title="1">page0Thumbail, err := extractThumbnailFromPDF(tf.Name(), dim)
        switch </span>{
        case err != nil:<span class="cov0" title="0">
                return &amp;PDFExtractResult{
                        SHA1Hex: fi.SHA1Hex,
                        Status:  "parse-error",
                        Err:     fmt.Errorf("thumbnail extraction failed with: %w", err),
                }</span>
        case len(page0Thumbail) &lt; 50:<span class="cov0" title="0">
                // assuming that very small images mean something went wrong
                page0Thumbail = nil</span>
        }
        // Extract additional pdf info.
        <span class="cov8" title="1">metadata, err := extractPDFMetadata(tf.Name())
        switch </span>{
        case err != nil:<span class="cov0" title="0">
                return &amp;PDFExtractResult{
                        SHA1Hex: fi.SHA1Hex,
                        Status:  "parse-error",
                        Err:     fmt.Errorf("pdf info extraction failed with: %w", err),
                }</span>
        }
        <span class="cov8" title="1">return &amp;PDFExtractResult{
                SHA1Hex:        fi.SHA1Hex,
                Status:         "success",
                Err:            nil,
                FileInfo:       fi,
                Text:           string(text),
                Page0Thumbnail: page0Thumbail,
                Metadata:       metadata,
                PDFExtra:       metadata.LegacyPDFExtra(),
        }</span>
}

// This is a hack to work around timeouts when processing certain PDFs with
// poppler. For some reason, the usual Kafka timeout catcher isn't working on
// these, maybe due to threading.
var BAD_PDF_SHA1HEX = []string{
        "011478a1e63a2a31eae1a93832a74cc95f220760",
        "018dfe9824de6d2ac068ce0f7dc9961bffa1b558",
        "057c7a9dfb611bfd52f7de6c39b2d5757c5e4e53",
        "06061af0707298c12932516d1bb7c2b6dc443824",
        "0641822e68c5a07538b967489fd19a1d5dc371a5",
        "09cba9b00494d12759c50cb914f1fb7c9746f5d1",
        "09db7c9f2efb496c974427a61e84292ae27fc702",
        "0a1c13cb8783bbbf248b2345b9890e2410aa3f0a",
        "0ccc6dc94f4e2d809fac8543870265c3421f3c9e",
        "0d1c1567ea70e7b922ba88ccb868ffc7ca18e75c",
        "10c6577a658bf6203557e2998b25ea9788f8adfe",
        "15a720921ce30da983fcd1bfa7fe9aeeda503e41",
        "1659881a31edc2d0e170f6bb26d32e74cc4ca387",
        "17e679b0ec9444fff2ea4d02caec05dd2de80ec3",
        "182749ad1db1d5e999d07f010bdcfc2978dadc88",
        "1a17a4fc43397804830cc29021281aac2e8cf0cb",
        "1cb166f0c0b5ffe673e6bbf6a29d77278711f253",
        "1d04e46b6848e6479dd90fe26bb11627044fb664",
        "1d967c95546d31edaaf0c3ef9ffcc11113a9e11a",
        "1f90194bf0c7fff1fe1ed5fff77a934c7a1b32a0",
        "20589d9dd0a22c8c938ad97b7f4f12648aa119fa",
        "2195e528fa1cf5f8ae3b2adcc516896016c3411f",
        "25ab9e6169f041be05844a9b4edd6574918af769",
        "281de904c4642a9be4f17b9774fc0a2bdc8a90e3",
        "2bd5322975653536550a039eb055174b2bf241b3",
        "2fc64da736175810918fd32c94c5068b0d660bcc",
        "32318fba9b05b2756b7362bcaa4722c92ed8d449",
        "336833c6fc968cd0938250dfc93c032a30111cfc",
        "362ad00bc24d650c8f11851f9e554fc560b73e7a",
        "373f84dfab4ed47047826e604e2918a9cd6a95b2",
        "3ac0b6e17e30d141871a0a5b127536919fe5aa19",
        "3c8a6a708da0dc1802f5f3e5267a49b3c25e1ffe",
        "3e5f9fb94e7314447a22f3d009419a922136177f",
        "3fad493c940137ce703f2f570ebb504e360c6df3",
        "40aa94602ab13e5a7d9df8c989fca4fa5c01239e",
        "427479c94d7d0e512f898bc7ff0b6f210069f902",
        "436c9183724f051b22c96285aa8ff1d2ba709574",
        "43a8c0abf0386d3e3397cf5e22a884761dd63db7",
        "445968ef735b228c08c3ff4238d99fc9f4824619",
        "447fa6b5a90742a86429a932f6608d8e141688c0",
        "45f014d7d631559dc7726e5c5513f1e7c91c48a9",
        "47577ff6d6876117ca69bec60a5764f7d2c2ec70",
        "4785181cec8944eee00ddb631a5dfc771b89bab7",
        "47db2db2cc976429568841a0496c0ab4ed7b5977",
        "481c0bae81873988fcc8662ba8a269e8823fdea2",
        "4c81129904f7976a50825595a3497ea7b52579ef",
        "4edc1402712fa6827c4501fed8042e9f4447829c",
        "50b3c5a3122272aca69855ef06b85d0b43a76eb1",
        "52fc9b3c5199ef395d410c7cee5961dc812e4d29",
        "53471346019947a88c1ba141fb829375527153b0",
        "58d9ae7dcb0a7dbbdfc58ad266030b037e9cd0ff",
        "59cfc843ebdb1c1e5db1efc76a40f46cb3bb06f0",
        "5ab98405b676ee81a6ca74fba51a9e4a6cff7311",
        "5c5b45c85eff07d4302844e00ec8baa57b988c60",
        "5e04779cbbae5ce88bb786064f756885dd6895fe",
        "5e6a3adde9f08c276c4efd72bfacb256f2ec35d9",
        "62247fe6b8d3ca50477cafddbe24bf63832d6674",
        "623ff84b616383d0a3e0dd8dbce12f0b5fe9a6ac",
        "646c4a654270606256397684204ff0f3d17be2e7",
        "64d821d728f9a3dc944b4c03be00feea0b57e314",
        "668b7d777203af4b261d21bf4669fc9b385062e1",
        "689b5cb3ddef213d612363a903f10d0358ea64d2",
        "6909f0b62d8b7835de3dec7777aad7f8ef507ee3",
        "74e617dc95555e8ca3aadd19d0c85b71cd77d1d9",
        "7596438d77444a7c4228bb96fa4b394ba7d7e23b",
        "75c2662a96ccc48891228df7c85eb7d4da9dd621",
        "771f1ca0007a6fbed5b4a434c73f524f715d33c1",
        "776859635e9dc01d97b0582f49c814ffbcb019fb",
        "781dafda896a9f5c30f3d0a011f79a3b79b574c4",
        "788672c7c2bcdecf6e2f6a2177c01e60f04d9cfb",
        "79d6cba3c6e577a0f3a3a9fe575680d38454938d",
        "7b8b7e8e4b789579a7d2fda329db52528383a652",
        "7c5c925cfb7c5a861b5c0a1d923308f9bedd335e",
        "7cfc0739be9c49d94272110a0a748256bdde9be6",
        "7daf61526ec825151f384cc1db510ca5237d5d80",
        "7e9d846f3bf9ce15cdb991b78cc870ab8a2bed76",
        "800e47a7ed214f7acac85cc29aa7b0f9c0e218ae",
        "8398b211a5ec4da1195a4ba1bc29ca8c0ac40f67",
        "859d7ec532a0bf3b52b17c7f2d8ecc58410c0aad",
        "88edcbab1cac2d70af5870422974afc253f4f0c6",
        "89860fc475fcb2a2d86c4544df52ec8fd5e6533f",
        "8dcaf4ef132900dd378f7be526c884b17452713b",
        "8e4f03c29ae1fe7227140ab4b625f375f6c00d31",
        "8ec1a17ec19ae8ade95b9bdc837236981e83fffb",
        "949dfb7d833da9576b2ccb9eb1ab5457469c53d3",
        "961ec451172f373f919c593737466300e42062cb",
        "976989fa6e447578d9ce16ec5b526f0e09d6df50",
        "977f23723027d7052df9b49eb467e6c0b9af93ff",
        "98b02eb70066c182c705ef4d14d8b723ad7f1fab",
        "993ca31f6974f8387bb18dd7d38987d290da8781",
        "9dbd05af3442e6f42d67868054751b76973f4171",
        "a1cc781c694a48e018f4de110b58f561aa212051",
        "a2298c137b9c8c8975bad62eea9224edb95e6952",
        "a2671738755ab8b24775e95375dc72f1ca4e5fd6",
        "a26f299fb97c646effeebd4c5e2968786bd0f781",
        "a48f9b7ad627909f76d780aa4208530304ece42c",
        "a69665d0b5d3b95f54f68406eee3ed50c67efb45",
        "a69665d0b5d3b95f54f68406eee3ed50c67efb45",
        "a8357c31837404f9ebd798999d546c9398ab3648",
        "a9162b9aef5e5da0897275fede1a6cff8cc93dfc",
        "abc9d264df446707b40d7c9f79befd0f89291e59",
        "ad038725bf6855a79f3c768ebe93c7103d14522f",
        "aef581bf42e76e527f5aed3b8958fd4e7a24819f",
        "b2b66b9c7f817a20144456f99c0be805602e8597",
        "b2d719120306b90eb8dd3580b699a61ec70556f4",
        "b4b8e18e27f102e59b2be2d58c7b54d0a0eb457a",
        "b5be7f409a3a2601208c5ce08cf52b9ac1094aae",
        "b5bf8b7467fb095c90adf3b49aa1687291e4469c",
        "b8b427e5b3d650ba9e03197f9c3917e25b878930",
        "bad48b89b639b5b7df2c6a2d5288181fcb8b0e35",
        "be0cda7642e9247b3ee41cd2017fa709aab4f344",
        "beff1b0c24aa99989be73c66dfb1d1e7578e370b",
        "c1b583fbd052572f08158d39ffe4d7510dadbebb",
        "c2526f75a013dc67b14ce1e2d0e4fc80bb93c6e1",
        "c4abbb284f4acaca9e8ceb88f842901984e84d33",
        "c58e028269c8dfd3a442f6745c81b4c0e8610c43",
        "c7220d1bf1e71fb755d9f26bbdd4c539dc162960",
        "c7687fa6f637c7d32a25be0e772867d87536d35c",
        "c7d8b37ec99cf0d987e60667f05299f200e18a5d",
        "c92b9ae9eefa07504950b405625aef54b48f0e1a",
        "ccb1debcfae006a3fc984e9e91309b9706a5c375",
        "cd611c765cbb0b3b7cb2fdc07d8f0b9cc93ec257",
        "cd8a7c3b8d850ebedc1ca791ccb37b9a2689f9c3",
        "d055c054c330f99ec011e37186d2b429339758fd",
        "d17b1e254cce82df5c6eb4fd492cef91e7e11558",
        "d188762a7e3ab5d4ee8a897204316513e4e636ec",
        "d613b9e4442f5d5d19ea6814fa9729bff7da7c85",
        "d6b0f405bf13c23d0e90c54eea527442786d1cd3",
        "d91d3830bf455e6dd782eee46218e35d29f07dfd",
        "da2211ee2dbc6dda36571976d810e2366a3d2504",
        "dbb3093a797e0ae83d39eb7b235ff85a17fd965c",
        "e01bb7256d77aea258313bb410dfcfc10512f420",
        "e2bf5d0a5885359381fe8ef2cd9290171d494e9b",
        "e2c3b8a2cf33d5e8972bc9ddb78373766a75e412",
        "e64714a81f60ab9286ec90cad682cb22e564fb6f",
        "e9d7716b4f94bbc3d94459b5fe9bb8b15cb2e433",
        "e9e84e17383e93a784a8471708619162b32fb399",
        "eac7df5f799983d5a7cc55d10b4d426dc557febf",
        "eaf84b2efd2f69c7b3f407f89ea66ac4c41fac36",
        "eb1b39fd7a874896688855a22efddef10272427c",
        "eb5fffaa590a52bcc3705b888c6ff9c4dc4c45b2",
        "ecc4b927c5e84e145c610876931bc261ae13769b",
        "edf8dcc8736f06afbaca0e01d60bd2c475403a3d",
        "ee2ee6ae2cf05128810d0d95bbe69bd263e140de",
        "ee9530a2c5a3d1e3813ccb51a55cc8b0d9b5dfc7",
        "ef1dfa325c21cff4cd8bb1a9b6c4ee6996d43c8f",
        "ef6749d9263a01f921ba7d72df0d17671d14e5f6",
        "f0ea221d8587cede25592266486e119d277f7096",
        "f68f9a9202a75d2aee35252e104d796f9515001e",
        "f9314d3bf2eac78a7d78d18adcccdb35542054ef",
        "f932ef936021a3b00842b481478c40868b9a007c",
        "fd9bd560662e070b222d63052830837829c490f0",
}
</pre>
		
		<pre class="file" id="file6" style="display: none">package pdfinfo

import (
        "bytes"
        "encoding/json"
        "log"
        "os/exec"
        "regexp"
        "strconv"
        "strings"
)

// Metadata groups output of various tools into a single struct.
type Metadata struct {
        PDFCPU  *PDFCPU `json:"pdfcpu,omitempty"`  // pdfcpu output, parsed into JSON.
        PDFInfo *Info   `json:"pdfinfo,omitempty"` // pdfinfo, parsed into JSON.
}

func (metadata Metadata) LegacyPDFExtra() *PDFExtra <span class="cov0" title="0">{
        return &amp;PDFExtra{
                Page0Height: metadata.PDFInfo.PageDim().Height,
                Page0Width:  metadata.PDFInfo.PageDim().Width,
                PageCount:   metadata.PDFInfo.Pages,
                PDFVersion:  metadata.PDFInfo.PDFVersion,
        }
}</span>

// PDFExtra was a free form dictionary in sandcrawler. Keep this here for
// compatibility.
//
// In [10]: pdf_document.pdf_id
// Out[10]: PDFId(permanent_id='070262676b9d8a3776b3a9e2c168f961',
// update_id='29245f594c8bea0fc7f2cc90ca1dd021')
type PDFExtra struct {
        Page0Height float64 `json:"page0height,omitempty"`  // in pts, we can parse "pdfinfo" output
        Page0Width  float64 `json:"page0width,omitempty"`   // in pts, we can parse "pdfinfo" output
        PageCount   int     `json:"page_count,omitempty"`   // "pdfinfo" "Pages"
        PermanentID string  `json:"permanent_id,omitempty"` // TODO: where do we get this from?
        UpdateID    string  `json:"update_id,omitempty"`    // TODO: where do we get this from?
        PDFVersion  string  `json:"pdf_version,omitempty"`  // PDF version: 1.5, ...
}

// PDFCPU structured output from pdfcpu tool.
type PDFCPU struct {
        Header struct {
                Creation string `json:"creation"`
                Version  string `json:"version"`
        } `json:"header"`
        Infos []struct {
                AppendOnly       bool     `json:"appendOnly"`
                Author           string   `json:"author"`
                Bookmarks        bool     `json:"bookmarks"`
                CreationDate     string   `json:"creationDate"`
                Creator          string   `json:"creator"`
                Encrypted        bool     `json:"encrypted"`
                Form             bool     `json:"form"`
                Hybrid           bool     `json:"hybrid"`
                Keywords         []string `json:"keywords"`
                Linearized       bool     `json:"linearized"`
                ModificationDate string   `json:"modificationDate"`
                Names            bool     `json:"names"`
                PageCount        int64    `json:"pageCount"`
                PageMode         string   `json:"pageMode"`
                PageSizes        []struct {
                        Height float64 `json:"height"`
                        Width  float64 `json:"width"`
                } `json:"pageSizes"`
                Permissions int64  `json:"permissions"`
                Producer    string `json:"producer"`
                Properties  struct {
                        PTEXFullbanner string `json:"PTEX.Fullbanner"`
                } `json:"properties"`
                Signatures         bool   `json:"signatures"`
                Source             string `json:"source"`
                Subject            string `json:"subject"`
                Tagged             bool   `json:"tagged"`
                Thumbnails         bool   `json:"thumbnails"`
                Title              string `json:"title"`
                Unit               string `json:"unit"`
                UsingObjectStreams bool   `json:"usingObjectStreams"`
                UsingXRefStreams   bool   `json:"usingXRefStreams"`
                Version            string `json:"version"`
                Watermarked        bool   `json:"watermarked"`
        } `json:"infos"`
}

// Info is a parsed pdfinfo output.
type Info struct {
        Title          string `json:"title"`
        Subject        string `json:"subject"`
        Keywords       string `json:"keywords"`
        Author         string `json:"author"`
        Creator        string `json:"creator"`
        Producer       string `json:"producer"`
        CreationDate   string `json:"creation_date"`
        ModDate        string `json:"mod_date"`
        CustomMetadata bool   `json:"custom_metadata"`
        MetadataStream bool   `json:"metadata_stream"`
        Tagged         bool   `json:"tagged"`
        UserProperties bool   `json:"user_properties"`
        Suspects       bool   `json:"suspects"`
        Form           string `json:"form"`
        JavaScript     bool   `json:"javascript"`
        Pages          int    `json:"pages"`
        Encrypted      bool   `json:"encrypted"`
        PageSize       string `json:"page_size"` // 595.276 x 841.89 pts (A4)
        PageRot        int    `json:"page_rot"`
        FileSize       int    `json:"filesize"`
        Optimized      bool   `json:"optimized"`
        PDFVersion     string `json:"pdf_version"`
}

// Dim groups width and height of a page.
type Dim struct {
        Width  float64
        Height float64
}

func (info *Info) PageDim() Dim <span class="cov8" title="1">{
        if info == nil </span><span class="cov8" title="1">{
                return Dim{}
        }</span>
        // 463.059 x 668.047 pts
        // 595 x 882 pts
        <span class="cov8" title="1">re := regexp.MustCompile(`(?&lt;width&gt;[0-9.]*)[\s]*x[\s]*(?&lt;height&gt;[0-9.]*)`)
        matches := re.FindStringSubmatch(info.PageSize)
        if len(matches) &lt; 3 </span><span class="cov8" title="1">{
                return Dim{}
        }</span>
        <span class="cov8" title="1">width, err := strconv.ParseFloat(matches[re.SubexpIndex("width")], 64)
        if err != nil </span><span class="cov0" title="0">{
                return Dim{}
        }</span>
        <span class="cov8" title="1">height, err := strconv.ParseFloat(matches[re.SubexpIndex("height")], 64)
        if err != nil </span><span class="cov0" title="0">{
                return Dim{}
        }</span>
        <span class="cov8" title="1">dim := Dim{
                Width:  width,
                Height: height,
        }
        return dim</span>
}

// ParseFile a filename into a structured metadata object. Requires pdfinfo and pdfcpu to be installed.
func ParseFile(filename string) (*Metadata, error) <span class="cov0" title="0">{
        var metadata = new(Metadata)
        info, err := runPdfInfo(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">metadata.PDFInfo = info
        pdfcpu, err := runPdfCpu(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">metadata.PDFCPU = pdfcpu
        return metadata, nil</span>
}

// ParseFile parses a pdf file. Requires pdfinfo executable to be installed.
func runPdfCpu(filename string) (*PDFCPU, error) <span class="cov0" title="0">{
        var buf bytes.Buffer
        cmd := exec.Command("pdfcpu", "info", "-j", filename)
        cmd.Stdout = &amp;buf
        if err := cmd.Run(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">var pdfcpu PDFCPU
        if err := json.Unmarshal(buf.Bytes(), &amp;pdfcpu); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;pdfcpu, nil</span>
}

// runPdfInfo parses a pdf file. Requires pdfinfo executable to be installed.
func runPdfInfo(filename string) (*Info, error) <span class="cov8" title="1">{
        var buf bytes.Buffer
        cmd := exec.Command("pdfinfo", filename)
        cmd.Stdout = &amp;buf
        if err := cmd.Run(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return ParseInfo(buf.String()), nil</span>
}

// ParseInfo pdfinfo output into an Info struct.
func ParseInfo(s string) *Info <span class="cov8" title="1">{
        info := Info{}
        for _, line := range strings.Split(s, "\n") </span><span class="cov8" title="1">{
                line = strings.TrimSpace(line)
                if len(line) == 0 </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">fields := strings.SplitN(line, ":", 2)
                if len(fields) != 2 </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">fields[0] = strings.TrimSpace(fields[0])
                fields[1] = strings.TrimSpace(fields[1])
                switch fields[0] </span>{
                case "Title":<span class="cov8" title="1">
                        info.Title = fields[1]</span>
                case "Subject":<span class="cov8" title="1">
                        info.Subject = fields[1]</span>
                case "Keywords":<span class="cov8" title="1">
                        info.Keywords = fields[1]</span>
                case "Author":<span class="cov8" title="1">
                        info.Author = fields[1]</span>
                case "Creator":<span class="cov8" title="1">
                        info.Creator = fields[1]</span>
                case "Producer":<span class="cov8" title="1">
                        info.Producer = fields[1]</span>
                case "CreationDate":<span class="cov8" title="1">
                        info.CreationDate = fields[1]</span>
                case "ModDate":<span class="cov8" title="1">
                        info.ModDate = fields[1]</span>
                case "Custom Metadata":<span class="cov8" title="1">
                        info.CustomMetadata = parseBool(fields[1])</span>
                case "Metadata Stream":<span class="cov8" title="1">
                        info.MetadataStream = parseBool(fields[1])</span>
                case "Tagged":<span class="cov8" title="1">
                        info.Tagged = parseBool(fields[1])</span>
                case "UserProperties":<span class="cov8" title="1">
                        info.UserProperties = parseBool(fields[1])</span>
                case "Suspects":<span class="cov8" title="1">
                        info.Suspects = parseBool(fields[1])</span>
                case "Form":<span class="cov8" title="1">
                        info.Form = fields[1]</span>
                case "JavaScript":<span class="cov8" title="1">
                        info.JavaScript = parseBool(fields[1])</span>
                case "Pages":<span class="cov8" title="1">
                        info.Pages = parseInt(fields[1])</span>
                case "Encrypted":<span class="cov8" title="1">
                        info.Encrypted = parseBool(fields[1])</span>
                case "Page size":<span class="cov8" title="1">
                        info.PageSize = fields[1]</span>
                case "Page rot":<span class="cov8" title="1">
                        info.PageRot = parseInt(fields[1])</span>
                case "File size":<span class="cov8" title="1">
                        info.FileSize = parseAnyInt(fields[1])</span>
                case "Optimized":<span class="cov8" title="1">
                        info.Optimized = parseBool(fields[1])</span>
                case "PDF version":<span class="cov8" title="1">
                        info.PDFVersion = fields[1]</span>
                default:<span class="cov0" title="0">
                        log.Printf("ignoring pdfinfo field: %v", fields[0])</span>
                }
        }
        <span class="cov8" title="1">return &amp;info</span>
}

// parseBool returns a bool from a string used in pdfinfo output, like "yes", and "no".
func parseBool(s string) bool <span class="cov8" title="1">{
        if s == "yes" </span><span class="cov8" title="1">{
                return true
        }</span>
        <span class="cov8" title="1">return false</span>
}

func parseInt(s string) int <span class="cov8" title="1">{
        v, err := strconv.Atoi(s)
        if err != nil </span><span class="cov0" title="0">{
                log.Println(err)
                return 0
        }</span>
        <span class="cov8" title="1">return v</span>
}

func parseAnyInt(s string) int <span class="cov8" title="1">{
        for _, tok := range strings.Fields(s) </span><span class="cov8" title="1">{
                v, err := strconv.Atoi(tok)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">return v</span>
        }
        <span class="cov0" title="0">return 0</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">// Package pidfile provides structure and helper functions to create and remove
// PID file. A PID file is usually a file used to store the process ID of a
// running process.
package pidfile // import "github.com/docker/docker/pkg/pidfile"

import (
        "bytes"
        "fmt"
        "os"
        "path/filepath"
        "runtime"
        "strconv"

        "golang.org/x/sys/unix"
)

// Alive returns true if process with a given pid is running. It only considers
// positive PIDs; 0 (all processes in the current process group), -1 (all processes
// with a PID larger than 1), and negative (-n, all processes in process group
// "n") values for pid are never considered to be alive.
func Alive(pid int) bool <span class="cov8" title="1">{
        if pid &lt; 1 </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">switch runtime.GOOS </span>{
        case "darwin":<span class="cov0" title="0">
                // OS X does not have a proc filesystem. Use kill -0 pid to judge if the
                // process exists. From KILL(2): https://www.freebsd.org/cgi/man.cgi?query=kill&amp;sektion=2&amp;manpath=OpenDarwin+7.2.1
                //
                // Sig may be one of the signals specified in sigaction(2) or it may
                // be 0, in which case error checking is performed but no signal is
                // actually sent. This can be used to check the validity of pid.
                err := unix.Kill(pid, 0)

                // Either the PID was found (no error) or we get an EPERM, which means
                // the PID exists, but we don't have permissions to signal it.
                return err == nil || err == unix.EPERM</span>
        default:<span class="cov8" title="1">
                _, err := os.Stat(filepath.Join("/proc", strconv.Itoa(pid)))
                return err == nil</span>
        }
}

// Read reads the "PID file" at path, and returns the PID if it contains a
// valid PID of a running process, or 0 otherwise. It returns an error when
// failing to read the file, or if the file doesn't exist, but malformed content
// is ignored. Consumers should therefore check if the returned PID is a non-zero
// value before use.
func Read(path string) (pid int, err error) <span class="cov8" title="1">{
        pidByte, err := os.ReadFile(path)
        if err != nil </span><span class="cov8" title="1">{
                return 0, err
        }</span>
        <span class="cov8" title="1">pid, err = strconv.Atoi(string(bytes.TrimSpace(pidByte)))
        if err != nil </span><span class="cov8" title="1">{
                return 0, nil
        }</span>
        <span class="cov8" title="1">if pid != 0 &amp;&amp; Alive(pid) </span><span class="cov8" title="1">{
                return pid, nil
        }</span>
        <span class="cov8" title="1">return 0, nil</span>
}

// Write writes a "PID file" at the specified path. It returns an error if the
// file exists and contains a valid PID of a running process, or when failing
// to write the file.
func Write(path string, pid int) error <span class="cov8" title="1">{
        if pid &lt; 1 </span><span class="cov8" title="1">{
                // We might be running as PID 1 when running docker-in-docker,
                // but 0 or negative PIDs are not acceptable.
                return fmt.Errorf("invalid PID (%d): only positive PIDs are allowed", pid)
        }</span>
        <span class="cov8" title="1">oldPID, err := Read(path)
        if err != nil &amp;&amp; !os.IsNotExist(err) </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">if oldPID != 0 </span><span class="cov8" title="1">{
                return fmt.Errorf("process with PID %d is still running", oldPID)
        }</span>
        <span class="cov8" title="1">return os.WriteFile(path, []byte(strconv.Itoa(pid)), 0o644)</span>
}
</pre>
		
		<pre class="file" id="file8" style="display: none">package blobproc

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "os"
        "os/exec"

        "github.com/miku/grobidclient"
)

var (
        ErrFileTooLarge = errors.New("file too large")
        ErrInvalidHash  = errors.New("invalid hash")
)

var DefaultBucket = "default" // TODO: what is it?

// Runner wraps all custom processing from a file path on disk to the S3 storage.
type Runner struct {
        Grobid            *grobidclient.Grobid // Grobid client wraps grobid service API access.
        MaxGrobidFileSize int64                // Do not send too large blobs to grobid.
        ConsolidateMode   bool                 // ConsolidateMode pass through argument to grobid.
        S3Wrapper         *WrapS3              // Wraps access to S3/seaweedfs.
}

// ProcessFulltextResult is a wrapped grobid response. TODO: we may just use
// the GrobidResult directly.
type ProcessFulltextResult struct {
        StatusCode int
        Status     string
        Error      error
        TEIXML     string
        SHA1       string // SHA1 of the originating PDF, not the TEIXML
}

// processFulltext wrap grobid access and returns parsed document or some
// information about errors.
func (runner *Runner) processFulltext(filename string) (*ProcessFulltextResult, error) <span class="cov8" title="1">{
        fi, err := os.Stat(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if fi.Size() &gt; runner.MaxGrobidFileSize </span><span class="cov0" title="0">{
                return &amp;ProcessFulltextResult{
                        Status: "blob-too-large", // TODO: not sure we need that immediately
                        Error:  ErrFileTooLarge,
                }, ErrFileTooLarge
        }</span>
        <span class="cov8" title="1">opts := &amp;grobidclient.Options{
                ConsolidateHeader:      runner.ConsolidateMode,
                ConsolidateCitations:   false, // "too expensive for now"
                IncludeRawCitations:    true,
                IncluseRawAffiliations: true,
                TEICoordinates:         []string{"ref", "figure", "persName", "formula", "biblStruct"},
                SegmentSentences:       true,
        }
        result, err := runner.Grobid.ProcessPDF(filename, "processFulltextDocument", opts)
        if err != nil </span><span class="cov0" title="0">{
                return &amp;ProcessFulltextResult{
                        Status:     "grobid-error",
                        StatusCode: -1,
                        Error:      err,
                        SHA1:       "",
                }, err
        }</span>
        <span class="cov8" title="1">switch </span>{
        case result.StatusCode == 200 &amp;&amp; len(result.Body) &gt; 12_000_000:<span class="cov0" title="0">
                err := fmt.Errorf("response XML too large: %d", len(result.Body))
                return &amp;ProcessFulltextResult{
                        Status: "error",
                        Error:  err,
                        SHA1:   result.SHA1,
                }, err</span>
        case result.StatusCode == 200:<span class="cov8" title="1">
                return &amp;ProcessFulltextResult{
                        Status:     "success",
                        StatusCode: result.StatusCode,
                        TEIXML:     string(result.Body),
                        Error:      nil,
                        SHA1:       result.SHA1,
                }, nil</span>
        default:<span class="cov0" title="0">
                return &amp;ProcessFulltextResult{
                        Status:     "error",
                        StatusCode: result.StatusCode,
                        Error:      fmt.Errorf("body: %v", string(result.Body)),
                }, nil</span>
        }
}

// RunGrobid and persist, returns the sha1 of the filename and any error.
func (sr *Runner) RunGrobid(filename string) (string, error) <span class="cov8" title="1">{
        result, err := sr.processFulltext(filename)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov8" title="1">opts := BlobRequestOptions{
                SHA1Hex: result.SHA1,
                Folder:  "grobid",
                Ext:     ".tei.xml",
                Bucket:  "sandcrawler",
        }
        _, err = sr.S3Wrapper.PutBlob(context.TODO(), &amp;opts)
        return result.SHA1, err</span>
}

func (sr *Runner) RunPdfToText(filename string) error <span class="cov8" title="1">{
        _, err := exec.LookPath("pdftotext")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">f, err := os.CreateTemp("", "blobproc-run-*")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{
                f.Close()
                os.Remove(f.Name())
        }</span>()
        // TODO: run w/ and w/o -layout and drop the shorter or empty one
        <span class="cov8" title="1">cmd := exec.Command("pdftotext", filename, f.Name())
        err = cmd.Run()
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">b, err := os.ReadFile(f.Name())
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">slog.Info("extracted fulltext", "path", f.Name(), "text", string(b))
        // sandcrawler uses python poppler, but pdftotext uses it too
        return nil</span>
}

func (sr *Runner) RunPdfThumbnail(filename string) error <span class="cov0" title="0">{ return nil }</span>
</pre>
		
		<pre class="file" id="file9" style="display: none">package blobproc

import (
        "crypto/sha1"
        "encoding/json"
        "errors"
        "fmt"
        "io"
        "io/fs"
        "log/slog"
        "net/http"
        "os"
        "path"
        "path/filepath"
        "strings"
        "time"

        "github.com/gorilla/mux"
)

const tempFilePattern = "blobprocd-*"

var errShortName = errors.New("short name")

// WebSpoolService saves web payload to a configured directory. TODO: add limit
// in size (e.g. 80% of disk or absolute value)
type WebSpoolService struct {
        Dir        string
        ListenAddr string
}

// spoolListEntry collects basic information about a spooled file.
type spoolListEntry struct {
        Name    string `json:"name"`
        Size    int64  `json:"size"`
        ModTime string `json:"t"`
        URL     string `json:"url"`
}

// shardedPath takes a filename (without path) and returns the full path
// including shards. If create is true, also create subdirectories, if
// necessary.
func (svc *WebSpoolService) shardedPath(filename string, create bool) (string, error) <span class="cov8" title="1">{
        if len(filename) &lt; 8 </span><span class="cov8" title="1">{
                return "", errShortName
        }</span>
        <span class="cov8" title="1">var (
                s0, s1 = filename[0:2], filename[2:4]
                dstDir = path.Join(svc.Dir, s0, s1)
        )
        if create </span><span class="cov0" title="0">{
                if _, err := os.Stat(dstDir); os.IsNotExist(err) </span><span class="cov0" title="0">{
                        if err := os.MkdirAll(dstDir, 0755); err != nil </span><span class="cov0" title="0">{
                                return "", err
                        }</span>
                }
        }
        <span class="cov8" title="1">return path.Join(dstDir, filename[4:]), nil</span>
}

// shardedPathExists returns true, if the sharded path for a given filename exists.
func (svc *WebSpoolService) shardedPathExists(filename string) (bool, error) <span class="cov0" title="0">{
        dst, err := svc.shardedPath(filename, false)
        if err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>
        <span class="cov0" title="0">if _, err := os.Stat(dst); err == nil </span><span class="cov0" title="0">{
                return true, nil
        }</span>
        <span class="cov0" title="0">return false, nil</span>
}

// shardedPathToIdentifier return the SHA1, given a sharded path.
func shardedPathToIdentifier(path string) string <span class="cov0" title="0">{
        parts := strings.Split(path, "/")
        if len(parts) &lt; 3 </span><span class="cov0" title="0">{
                return ""
        }</span>
        <span class="cov0" title="0">n := len(parts)
        return parts[n-3] + parts[n-2] + parts[n-1]</span>
}

// SpoolListHandler returns a single, long jsonlines response with information
// about all files in the spool directory.
func (svc *WebSpoolService) SpoolListHandler(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        var (
                entry spoolListEntry
                enc   = json.NewEncoder(w)
        )
        err := filepath.Walk(svc.Dir, func(path string, info fs.FileInfo, err error) error </span><span class="cov0" title="0">{
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if info.IsDir() </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">id := shardedPathToIdentifier(path)
                if len(id) == 0 </span><span class="cov0" title="0">{
                        slog.Error("zero length id")
                        w.WriteHeader(http.StatusInternalServerError)
                        return fmt.Errorf("zero length id")
                }</span>
                <span class="cov0" title="0">entry = spoolListEntry{
                        Name:    id,
                        Size:    info.Size(),
                        ModTime: info.ModTime().Format(time.RFC3339),
                        URL:     fmt.Sprintf("http://%v/spool/%v", svc.ListenAddr, id),
                }
                if err := enc.Encode(entry); err != nil </span><span class="cov0" title="0">{
                        slog.Error("encoding error", "err", err)
                        w.WriteHeader(http.StatusInternalServerError)
                        return err
                }</span>
                <span class="cov0" title="0">return nil</span>
        })
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to list files", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
        }</span>
}

// SpoolStatusHandler returns HTTP 200, if a given file is in the spool
// directory and HTTP 404, if the file is not in the spool directory.
func (svc *WebSpoolService) SpoolStatusHandler(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        var (
                vars   = mux.Vars(r)
                digest = vars["id"]
        )
        if len(digest) != 40 </span><span class="cov0" title="0">{
                slog.Debug("invalid id", "id", digest)
                w.WriteHeader(http.StatusBadRequest)
        }</span> else<span class="cov0" title="0"> {
                ok, err := svc.shardedPathExists(digest)
                switch </span>{
                case err != nil:<span class="cov0" title="0">
                        w.WriteHeader(http.StatusInternalServerError)</span>
                case ok:<span class="cov0" title="0">
                        w.WriteHeader(http.StatusOK)</span>
                default:<span class="cov0" title="0">
                        w.WriteHeader(http.StatusNotFound)</span>
                }
        }
}

// BlobHandler receives binary blobs and saves them on disk. This handler
// returns as soon as the file has been written into the spool directory of the
// service, using a sharded SHA1 as path.
func (svc *WebSpoolService) BlobHandler(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        started := time.Now()
        tmpf, err := os.CreateTemp("", tempFilePattern)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to create temporary file", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">defer os.Remove(tmpf.Name())
        var (
                h  = sha1.New()
                mw = io.MultiWriter(h, tmpf)
        )
        n, err := io.Copy(mw, r.Body)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to drain response body", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">if err := tmpf.Close(); err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to close temporary file", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">if n != r.ContentLength </span><span class="cov0" title="0">{
                slog.Error("content length mismatch", "n", n, "length", r.ContentLength)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">var (
                digest   = fmt.Sprintf("%x", h.Sum(nil))
                spoolURL = fmt.Sprintf("http://%v/spool/%v", svc.ListenAddr, digest)
        )
        dst, err := svc.shardedPath(digest, true)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("could not determine sharded path", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">ok, err := svc.shardedPathExists(digest)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("could not determine sharded path", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">if ok </span><span class="cov0" title="0">{
                f, err := os.Open(dst)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("already uploaded, but file not readable", "err", err)
                        w.WriteHeader(http.StatusInternalServerError)
                        return
                }</span>
                <span class="cov0" title="0">defer f.Close()
                fi, err := f.Stat()
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("failed to stat file", "err", err)
                        w.WriteHeader(http.StatusInternalServerError)
                        return
                }</span>
                <span class="cov0" title="0">if r.ContentLength == fi.Size() </span><span class="cov0" title="0">{
                        slog.Debug("found existing file in spool dir, skipping", "url", spoolURL)
                        w.Header().Add("Location", spoolURL)
                        w.WriteHeader(http.StatusAccepted)
                        return
                }</span>
                <span class="cov0" title="0">slog.Debug("warning: found existing file, but size differ, overwriting")</span>
        }
        <span class="cov0" title="0">if err := os.Rename(tmpf.Name(), dst); err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to rename", "err", err)
                w.WriteHeader(http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">slog.Debug("spooled file", "file", dst, "url", spoolURL, "t", time.Since(started))
        w.Header().Add("Location", spoolURL)
        w.WriteHeader(http.StatusAccepted)</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
